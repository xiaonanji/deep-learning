{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.7.1+cu110', True, '4.2.2')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from transformers import BertForTokenClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import re\n",
    "import random\n",
    "\n",
    "import json\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "torch.__version__, torch.cuda.is_available(), transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 100\n",
    "BATCH_SIZE = 64\n",
    "# PRETRAIN_MODEL = 'bert-base-cased' #'../input/pytorch-bert-ner-2/pytorch_bert_ner_model'\n",
    "TRUNCATING_TYPE = 'pre'\n",
    "PADDING_TYPE = 'post'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(device)\n",
    "print(n_gpu)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(PRETRAIN_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained('C:\\\\Users\\\\stick\\\\kaggle\\\\tokenizer')\n",
    "model = BertForTokenClassification.from_pretrained('C:\\\\Users\\\\stick\\\\kaggle\\\\pytorch_bert_ner_model_v2')\n",
    "\n",
    "# model = BertForTokenClassification.from_pretrained('../input/pytorch-bert-ner/pytorch_bert_ner_model')\n",
    "model = model.to(device)\n",
    "\n",
    "tag_values = ['O', 'B-D', 'I-D', 'PAD']\n",
    "\n",
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower())\n",
    "\n",
    "def correct_word_broken(tu):\n",
    "    for i in range(len(tu)):\n",
    "        (token, tag) = tu[i]\n",
    "        if i > 0:\n",
    "            (previous_token, previous_tag) = tu[i-1]\n",
    "            if previous_tag == 'B-D' and token.startswith('##'):\n",
    "                tu[i] = (token, previous_tag)\n",
    "    return tu\n",
    "\n",
    "def remove_super_tags(tags):\n",
    "    new_set = set()\n",
    "    for s in tags:\n",
    "        remove = False\n",
    "        for ss in tags:\n",
    "            if ss in s and s > ss:\n",
    "                remove = True\n",
    "                break\n",
    "        if not remove:\n",
    "            new_set.add(s)\n",
    "\n",
    "    return new_set\n",
    "\n",
    "def get_dataset_tags(tokenized_sentence, pred_tags):\n",
    "    dataset_names = set()\n",
    "    dataset_name = ''\n",
    "    tu = correct_word_broken(list(zip(tokenized_sentence, pred_tags)))\n",
    "#     for t in tu:\n",
    "#         print(t)\n",
    "    found_start = False\n",
    "    for (token, tag) in tu:\n",
    "        if not found_start and tag == 'B-D' and not token.startswith('##'): # Found the starting position\n",
    "            dataset_name += token\n",
    "            found_start = True\n",
    "            continue\n",
    "        \n",
    "        if found_start:\n",
    "            if tag == 'B-D' or tag == 'I-D':\n",
    "                if token.startswith('##'):\n",
    "                    dataset_name += token.replace('##', '')\n",
    "                else:\n",
    "                    dataset_name += ' ' + token\n",
    "            else:\n",
    "                found_start = False\n",
    "                dataset_name = dataset_name.strip()\n",
    "                if (dataset_name[0] >= 'A' and dataset_name[0] <= 'Z' or dataset_name[0] >= 'a' and dataset_name[0] <= 'z') and not dataset_name.startswith('and '): \n",
    "                    dataset_names.add(clean_text(dataset_name))\n",
    "                    dataset_name = ''\n",
    "    return dataset_names\n",
    "\n",
    "def is_sentence_worth_predict(words):\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if len(w) > 0 and w[0] >= 'A' and w[0] <= 'Z':\n",
    "            count += 1\n",
    "            if count >= 3:\n",
    "                return True\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\n",
    "    './sentence_test.csv',\n",
    "    index_col=None,\n",
    "    header='infer',\n",
    "    keep_default_na=False,\n",
    "#     names=['fid', 'sid', 'sentence', 'labels', 'dedup_labels'],\n",
    "    dtype={\n",
    "        'fid': 'str',\n",
    "        'sid': 'str', \n",
    "        'sentence': 'str',\n",
    "        'labels': 'str',\n",
    "        'dedup_labels': 'str'\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringDataset:\n",
    "    def __init__(self, fids, sids, input_ids, masks):\n",
    "        self.fids = fids\n",
    "        self.sids = sids\n",
    "        self.input_ids = input_ids\n",
    "        self.masks = masks\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        b_fids = self.fids[item]\n",
    "        b_sids = self.sids[item]\n",
    "        b_input_ids = self.input_ids[item]\n",
    "        b_masks = self.masks[item]\n",
    "        \n",
    "#         print(b_fids)\n",
    "#         print(b_sids)\n",
    "#         print(b_input_ids)\n",
    "#         print(b_tokenized_sentences)\n",
    "#         print(b_masks)\n",
    "\n",
    "        return {\n",
    "            \"b_fids\": b_fids,\n",
    "            \"b_sids\": b_sids,\n",
    "            \"b_input_ids\": torch.tensor(b_input_ids, dtype=torch.long),\n",
    "            \"b_masks\": torch.tensor(b_masks, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1506 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Prepare bert tokenized sentences\n",
    "tokenized_sentences = []\n",
    "fids = []\n",
    "sids = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    fid = row['fid']\n",
    "    sid = row['sid']\n",
    "    sentence = row['sentence']\n",
    "    tokenized_sentence = tokenizer.tokenize(sentence)\n",
    "    tokenized_sentences.append(tokenized_sentence)\n",
    "    fids.append(fid)\n",
    "    sids.append(sid)\n",
    "\n",
    "input_ids = pad_sequences(\n",
    "    [tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_sentences], \n",
    "    maxlen=MAX_LEN, \n",
    "    dtype='long', \n",
    "    value=0.0, \n",
    "    truncating=TRUNCATING_TYPE, \n",
    "    padding=PADDING_TYPE\n",
    ")\n",
    "\n",
    "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]\n",
    "\n",
    "scoring_dataset = ScoringDataset(\n",
    "    fids=fids,\n",
    "    sids=sids,\n",
    "    input_ids=input_ids,\n",
    "    masks=attention_masks,\n",
    ")\n",
    "\n",
    "scoring_dataloader = DataLoader(\n",
    "    scoring_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(755, 48312)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scoring_dataloader), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b_fids': ['dc107d04-1082-426a-b616-e755486c8627', '430aa11c-0283-411b-8edc-08f5df3db258', '14848a9b-13a7-41c3-b49f-ba725695e497', '5c3de175-0bcf-4165-a5c3-c3ced789d2f6', 'da369ee6-2d60-402c-b3bf-05f44df77c78', 'c342d0c4-abe5-4c33-af32-257ef120d932', '7fd5e4c7-4577-4b2a-8f3f-2849ccb92ec6', '5509b730-b7d5-459f-aa6b-72d84a81e97f', '170113f9-399c-489e-ab53-2faf5c64c5bc', '81eaf522-1f9f-48b6-9cfa-8e586b8d664a', '930f4366-2fcd-49a8-b75e-6b0864cb2b3e', '4a2bd823-e642-4ad9-b8e6-796ae4db9734', '170113f9-399c-489e-ab53-2faf5c64c5bc', 'ccb0c3a8-9492-4c28-aa38-25a1fb40d6d5', 'be69c37f-95de-429e-ba8c-70a698fcae03', '5f735753-787c-4c42-bd04-877f8a8c5464', '0cbde738-c072-47e7-92b5-b6ccb5661f2d', '5ef54d76-d304-4fd3-8ea3-cc89ea261405', '0d939d09-bd11-4c97-840e-43076458f11d', 'd8621959-e8cd-479d-9182-b5d741de5b8d', 'e1aac6e3-c1d0-498c-a2bd-a7b97464590d', '34a240e7-bd70-4d96-a9f6-007db33d6bd8', 'a282c913-0477-442d-8006-690ca3b5e34c', 'e63cf45b-4da7-49d1-8d55-698f4fbb9bd7', '61bdb1f4-b3ea-4d12-b4b3-40064e2b30a4', '2987fc66-373e-4b91-8478-4d045abbba3d', '2b5a13fc-314b-4686-966c-add23f33b4c7', 'a2c28b46-4636-4332-8bf1-f862d23cddd3', 'a1cabbdc-df9a-4c62-8712-9cde121f82d7', '75a69da1-824f-41d9-8856-aa31d97dcb91', '9769f5b7-4a33-4b91-9e3b-1a42e8f9e2ea', '641fb86e-2a0a-4174-91f4-4aa1b3705413', '6f6b0ee6-3495-4c09-8afe-50c04986e032', '81b13560-8786-45c7-a205-3fe46404e338', '91a5477a-cbb9-45da-ba9d-88a5635155f7', '0cbde738-c072-47e7-92b5-b6ccb5661f2d', 'a1055f67-9c8f-458a-985a-de20f3372d4b', 'c12a3ad2-17bc-4b8b-8779-77ba2680ae96', '51a4d297-6250-44ef-9efe-7ed745979c95', '5c03bd06-ffd6-4c03-aa5b-e91c5de30c61', '9bf4159a-7270-4484-9fd7-1dfa93413038', '92aa14f3-fac8-4cba-8d44-6bfc3dae13da', '3d61cdd8-240e-4202-9837-db4263fd196a', '75a69da1-824f-41d9-8856-aa31d97dcb91', '4a1152f5-09dd-4ab8-b7e6-59f99df468a2', 'dd6df078-2010-42fa-ad30-9c302d2ba55b', '44962135-7ae6-4ede-8228-1653190b0605', '430aa11c-0283-411b-8edc-08f5df3db258', 'a50bb821-b61d-4d79-904a-53b4e93ef9b0', '5509b730-b7d5-459f-aa6b-72d84a81e97f', '1765da81-b651-4f97-9eb7-7c6023b374c7', '16601e12-234f-4f13-93f4-aab6c8b5042e', 'c82e4146-9a3e-45bd-8bf8-4866140b7412', 'f562ec7f-eeef-482c-8a51-203eea71d072', 'ce60fabe-180c-43ab-85a9-4d896ee8b470', 'c12a3ad2-17bc-4b8b-8779-77ba2680ae96', 'f5af8851-3cc4-4675-a0ee-4bc61c78027d', 'ec5813c1-9351-4dde-b450-2f11ac08cb46', '6ab7cec6-e823-4c6d-91b9-33dcaa1d55db', '89445f76-6381-4f8a-b9bb-559638e3e8a8', 'db54d3c5-8a69-4bb6-a6da-059a4dd7c9a8', '10a04f93-11e4-474a-b04e-61b7303dc779', 'c342d0c4-abe5-4c33-af32-257ef120d932', 'cda4ee91-ec66-4250-883d-d2c9dbf351fe'], 'b_sids': ['S2682021', 'S4365895', 'S772899', 'S1088866', 'S856664', 'S1309749', 'S2267516', 'S4287527', 'S4546280', 'S2152077', 'S2295672', 'S3039678', 'S4541563', 'S2326508', 'S4067676', 'S2108989', 'S4975364', 'S1151874', 'S4206145', 'S2777284', 'S2002265', 'S2605786', 'S1776826', 'S3198239', 'S938658', 'S5179321', 'S2131222', 'S6541965', 'S2113365', 'S3343309', 'S6365823', 'S126917', 'S1513799', 'S2394065', 'S2552893', 'S4909154', 'S2250766', 'S5452089', 'S3933725', 'S3808050', 'S6451189', 'S5251210', 'S3114337', 'S3350447', 'S3621626', 'S4347428', 'S1273560', 'S4436664', 'S5364417', 'S4311610', 'S2750453', 'S2417695', 'S3148095', 'S431963', 'S5948255', 'S5510906', 'S2250043', 'S830547', 'S499402', 'S2644635', 'S4063449', 'S3511505', 'S2260846', 'S6630745'], 'b_input_ids': tensor([[ 3017,  2924,  1182,  ...,     0,     0,     0],\n",
      "        [ 4201,  2904,  5151,  ...,     0,     0,     0],\n",
      "        [ 1249,  1573, 24830,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  138, 20564, 12090,  ...,     0,     0,     0],\n",
      "        [  142,  3101,  1182,  ...,     0,     0,     0],\n",
      "        [ 1170,  5193,  3112,  ..., 10044,   114,   119]]), 'b_masks': tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])}\n"
     ]
    }
   ],
   "source": [
    "for d in scoring_dataloader:\n",
    "    print(d)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dl(scoring_dataloader):\n",
    "    predicted_tags = []\n",
    "    print(f'In total {len(scoring_dataloader)} batches to process')\n",
    "    processed = 0\n",
    "    model.eval()\n",
    "    for batch in scoring_dataloader:\n",
    "        b_fids = batch['b_fids']\n",
    "        b_sids = batch['b_sids']\n",
    "        b_input_ids = batch['b_input_ids'].to(device).to(torch.int64)\n",
    "        b_input_masks = batch['b_masks'].to(device).to(torch.int64)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_masks)\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "#         print(logits)\n",
    "        predictions = [list(p) for p in np.argmax(logits, axis=2)]\n",
    "#         print(predictions)\n",
    "        pred_tags = []\n",
    "        for r in predictions:\n",
    "            pred_tags.append([tag_values[ri] for ri in r])\n",
    "    \n",
    "        for fid, sid, pt in zip(b_fids, b_sids, pred_tags):\n",
    "            sentence = test_df[test_df['sid']==sid]['sentence'].values[0]\n",
    "            if 'B-D' in pt or 'I-D' in pt:\n",
    "                tokenized_sentence = tokenizer.tokenize(sentence)\n",
    "                dataset_names = get_dataset_tags(tokenized_sentence, pt)\n",
    "                predicted_tags.append((fid, sid, '|'.join(dataset_names)))\n",
    "            else:\n",
    "                if \"Alzheimer's Disease Neuroimaging Initiative (ADNI)\" in sentence:\n",
    "                    predicted_tags.append((fid, sid, clean_text(\"Alzheimer's Disease Neuroimaging Initiative (ADNI)\")))\n",
    "                elif 'ADNI' in sentence:\n",
    "                    predicted_tags.append((fid, sid, 'adni'))\n",
    "                else:\n",
    "                    predicted_tags.append((fid, sid, ''))\n",
    "                \n",
    "        processed += 1\n",
    "        if processed % 100 == 0:\n",
    "            print(f'{processed} processed')\n",
    "            \n",
    "    return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(test_df, debug=False):\n",
    "    predicted_tags = []\n",
    "    print(f'In total {len(test_df)} sentences to process')\n",
    "    processed = 0\n",
    "    for index, row in test_df.iterrows():\n",
    "        sentence = row['sentence']\n",
    "        \n",
    "        words = word_tokenize(sentence)\n",
    "#         if not is_sentence_worth_predict(words):\n",
    "#             continue  \n",
    "        tokenized_sentence = []\n",
    "        for w in words:\n",
    "            tokenized_word = tokenizer.tokenize(w)\n",
    "            tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        input_ids = pad_sequences(\n",
    "            [tokenizer.convert_tokens_to_ids(tokenized_sentence)], \n",
    "            maxlen=MAX_LEN, \n",
    "            dtype='long', \n",
    "            value=0.0, \n",
    "            truncating=TRUNCATING_TYPE, \n",
    "            padding=PADDING_TYPE\n",
    "        )\n",
    "\n",
    "        attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]\n",
    "\n",
    "        input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "        attention_masks = torch.tensor(attention_masks, dtype=torch.float)\n",
    "\n",
    "        model.eval()\n",
    "        b_input_ids = input_ids.to(device).to(torch.int64)\n",
    "        b_input_mask = attention_masks.to(device).to(torch.int64)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        predictions = np.argmax(logits, axis=2)[0]\n",
    "        pred_tags = [tag_values[w] for w in predictions]\n",
    "        if debug:\n",
    "            for p1, p2 in zip(tokenized_sentence, pred_tags):\n",
    "                print(p1, p2)\n",
    "        if 'B-D' in pred_tags or 'I-D' in pred_tags:\n",
    "            dataset_names = get_dataset_tags(tokenized_sentence, pred_tags)\n",
    "            predicted_tags.append('|'.join(dataset_names))\n",
    "#             pred_dataset_tags.update(dataset_names)\n",
    "#             print(f'{s}: {dataset_names}')\n",
    "        else:\n",
    "            if \"Alzheimer's Disease Neuroimaging Initiative (ADNI)\" in sentence:\n",
    "                predicted_tags.append((fid, sid, clean_text(\"Alzheimer's Disease Neuroimaging Initiative (ADNI)\")))\n",
    "            elif 'ADNI' in sentence:\n",
    "                predicted_tags.append((fid, sid, 'adni'))\n",
    "            else:\n",
    "                predicted_tags.append((fid, sid, ''))\n",
    "        \n",
    "        processed += 1\n",
    "        if processed % 1000 == 0:\n",
    "            print(f'{processed} processed')\n",
    "      \n",
    "    return predicted_tags\n",
    "#     return remove_super_tags(pred_dataset_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 48312 sentences to process\n",
      "1000 processed\n",
      "2000 processed\n",
      "3000 processed\n",
      "4000 processed\n",
      "5000 processed\n",
      "6000 processed\n",
      "7000 processed\n",
      "8000 processed\n",
      "9000 processed\n",
      "10000 processed\n",
      "11000 processed\n",
      "12000 processed\n",
      "13000 processed\n",
      "14000 processed\n",
      "15000 processed\n",
      "16000 processed\n",
      "17000 processed\n",
      "18000 processed\n",
      "19000 processed\n",
      "20000 processed\n",
      "21000 processed\n",
      "22000 processed\n",
      "23000 processed\n",
      "24000 processed\n",
      "25000 processed\n",
      "26000 processed\n",
      "27000 processed\n",
      "28000 processed\n",
      "29000 processed\n",
      "30000 processed\n",
      "31000 processed\n",
      "32000 processed\n",
      "33000 processed\n",
      "34000 processed\n",
      "35000 processed\n",
      "36000 processed\n",
      "37000 processed\n",
      "38000 processed\n",
      "39000 processed\n",
      "40000 processed\n",
      "41000 processed\n",
      "42000 processed\n",
      "43000 processed\n",
      "44000 processed\n",
      "45000 processed\n",
      "46000 processed\n",
      "47000 processed\n",
      "48000 processed\n",
      "dataframe verion runtime: 774.8628721237183\n",
      "In total 755 batches to process\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'sentence' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-271-284e5af9094f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpred_v2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_dl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'dataloader verion runtime: {end-start}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-269-475d3471c76c>\u001b[0m in \u001b[0;36mpredict_dl\u001b[1;34m(scoring_dataloader)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mpredicted_tags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'|'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                     \u001b[0mpredicted_tags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Alzheimer's Disease Neuroimaging Initiative (ADNI)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;34m'ADNI'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'sentence' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "pred_v1 = predict_df(test_df)\n",
    "end = time.time()\n",
    "print(f'dataframe verion runtime: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 755 batches to process\n",
      "100 processed\n",
      "200 processed\n",
      "300 processed\n",
      "400 processed\n",
      "500 processed\n",
      "600 processed\n",
      "700 processed\n",
      "dataloader verion runtime: 313.8321304321289\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pred_v2 = predict_dl(scoring_dataloader)\n",
    "end = time.time()\n",
    "print(f'dataloader verion runtime: {end-start}')\n",
    "\n",
    "test_df['predicted'] = pred_v1\n",
    "\n",
    "cleaned_dedup_labels = []\n",
    "for index, row in test_df.iterrows():\n",
    "    dedup_labels = row['dedup_labels']\n",
    "    if dedup_labels == '':\n",
    "        cleaned_dedup_labels.append(dedup_labels)\n",
    "    else:\n",
    "        dedup_label_list = dedup_labels.split('||')\n",
    "        cleaned_dedup_labels.append('|'.join([clean_text(dl) for dl in dedup_label_list]))\n",
    "test_df['cleaned_dedup_labels'] = cleaned_dedup_labels\n",
    "\n",
    "pred_v2_df = pd.DataFrame.from_records(pred_v2, columns =['fid', 'sid', 'pred_v2'])\n",
    "combined = pd.merge(test_df, pred_v2_df, on=[\"fid\", \"sid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_results = combined[combined['cleaned_dedup_labels'] != '']\n",
    "same = has_results[has_results.cleaned_dedup_labels == has_results.pred_v2]\n",
    "diff = has_results[has_results.cleaned_dedup_labels != has_results.pred_v2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9257270693512304 8276 664\n"
     ]
    }
   ],
   "source": [
    "print(len(same)/(len(same)+len(diff)), len(same), len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>sid</th>\n",
       "      <th>pred_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42065</th>\n",
       "      <td>d2be42c9-2895-4ca8-8ab1-9079123e2984</td>\n",
       "      <td>S410090</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        fid      sid pred_v2\n",
       "42065  d2be42c9-2895-4ca8-8ab1-9079123e2984  S410090        "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_v2_df[pred_v2_df['sid'] == 'S410090']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48308"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined[combined.predicted == combined.pred_v2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'international best track archive for climate stewardship|ibtracs'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff[diff['sid'] == 'S341009'].cleaned_dedup_labels.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>sid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>dedup_labels</th>\n",
       "      <th>predicted</th>\n",
       "      <th>cleaned_dedup_labels</th>\n",
       "      <th>pred_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26309</th>\n",
       "      <td>12620b5b-ca11-40fb-880b-096fff3d94c4</td>\n",
       "      <td>S604797</td>\n",
       "      <td>Of them, the main are: the Baltimore Longitudi...</td>\n",
       "      <td>Baltimore Longitudinal Study of Aging||Baltimo...</td>\n",
       "      <td>Baltimore Longitudinal Study of Aging (BLSA)</td>\n",
       "      <td></td>\n",
       "      <td>baltimore longitudinal study of aging blsa</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21490</th>\n",
       "      <td>c08d58e8-a21b-4e8a-b816-8923251ea9c2</td>\n",
       "      <td>S697761</td>\n",
       "      <td>We also examined ASA children's health and dev...</td>\n",
       "      <td>Early Childhood Longitudinal Study</td>\n",
       "      <td>Early Childhood Longitudinal Study</td>\n",
       "      <td>(4ef2b977-2e2d-41f5-8ed6-3f44c691f620, S794046, )</td>\n",
       "      <td>early childhood longitudinal study</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25926</th>\n",
       "      <td>6e3137f2-1cd7-47ba-b1c4-b32e242aac58</td>\n",
       "      <td>S1953813</td>\n",
       "      <td>The following data sets for the period 1982-20...</td>\n",
       "      <td>Optimum Interpolation Sea Surface Temperature</td>\n",
       "      <td>Optimum Interpolation Sea Surface Temperature</td>\n",
       "      <td>(4ef2b977-2e2d-41f5-8ed6-3f44c691f620, S794046, )</td>\n",
       "      <td>optimum interpolation sea surface temperature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44315</th>\n",
       "      <td>4a2bd823-e642-4ad9-b8e6-796ae4db9734</td>\n",
       "      <td>S3030914</td>\n",
       "      <td>Survey of Earned DoctoratesSex; age; race-ethn...</td>\n",
       "      <td>Survey of Earned Doctorates</td>\n",
       "      <td>Survey of Earned Doctorates</td>\n",
       "      <td>(4ef2b977-2e2d-41f5-8ed6-3f44c691f620, S794046, )</td>\n",
       "      <td>survey of earned doctorates</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13780</th>\n",
       "      <td>66a3dbe4-352b-4dad-a492-1e039df41520</td>\n",
       "      <td>S2522772</td>\n",
       "      <td>The TC record is taken from the International ...</td>\n",
       "      <td>IBTrACS</td>\n",
       "      <td>IBTrACS</td>\n",
       "      <td>ibtracs|international best track archive for c...</td>\n",
       "      <td>ibtracs</td>\n",
       "      <td>ibtracs|international best track archive for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>676acdae-e2f1-498a-9d40-cea8b531ea67</td>\n",
       "      <td>S2353187</td>\n",
       "      <td>As in our prior work , we used tensor-based mo...</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>ADNI</td>\n",
       "      <td></td>\n",
       "      <td>adni</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7798</th>\n",
       "      <td>2cc7485e-194d-41d4-8359-a6446cc50f75</td>\n",
       "      <td>S2517292</td>\n",
       "      <td>The filling rate of TCs after making landfall ...</td>\n",
       "      <td>IBTrACS</td>\n",
       "      <td>IBTrACS</td>\n",
       "      <td></td>\n",
       "      <td>ibtracs</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29013</th>\n",
       "      <td>147b87df-e46c-4d8a-a03a-00d7da262ac0</td>\n",
       "      <td>S3084963</td>\n",
       "      <td>This report documents the design, development,...</td>\n",
       "      <td>Early Childhood Longitudinal Study</td>\n",
       "      <td>Early Childhood Longitudinal Study</td>\n",
       "      <td>(4ef2b977-2e2d-41f5-8ed6-3f44c691f620, S794046, )</td>\n",
       "      <td>early childhood longitudinal study</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29355</th>\n",
       "      <td>8bd335ea-1351-4fba-99f8-53669c3c921d</td>\n",
       "      <td>S2083516</td>\n",
       "      <td>[31] [32] [33] All C-11 Pittsburgh compound B ...</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>pittsburgh compound</td>\n",
       "      <td>adni</td>\n",
       "      <td>pittsburgh compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33185</th>\n",
       "      <td>147b87df-e46c-4d8a-a03a-00d7da262ac0</td>\n",
       "      <td>S3085729</td>\n",
       "      <td>Additional details may be found in the Early C...</td>\n",
       "      <td>Early Childhood Longitudinal Study</td>\n",
       "      <td>Early Childhood Longitudinal Study</td>\n",
       "      <td>(4ef2b977-2e2d-41f5-8ed6-3f44c691f620, S794046, )</td>\n",
       "      <td>early childhood longitudinal study</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        fid       sid  \\\n",
       "26309  12620b5b-ca11-40fb-880b-096fff3d94c4   S604797   \n",
       "21490  c08d58e8-a21b-4e8a-b816-8923251ea9c2   S697761   \n",
       "25926  6e3137f2-1cd7-47ba-b1c4-b32e242aac58  S1953813   \n",
       "44315  4a2bd823-e642-4ad9-b8e6-796ae4db9734  S3030914   \n",
       "13780  66a3dbe4-352b-4dad-a492-1e039df41520  S2522772   \n",
       "...                                     ...       ...   \n",
       "2073   676acdae-e2f1-498a-9d40-cea8b531ea67  S2353187   \n",
       "7798   2cc7485e-194d-41d4-8359-a6446cc50f75  S2517292   \n",
       "29013  147b87df-e46c-4d8a-a03a-00d7da262ac0  S3084963   \n",
       "29355  8bd335ea-1351-4fba-99f8-53669c3c921d  S2083516   \n",
       "33185  147b87df-e46c-4d8a-a03a-00d7da262ac0  S3085729   \n",
       "\n",
       "                                                sentence  \\\n",
       "26309  Of them, the main are: the Baltimore Longitudi...   \n",
       "21490  We also examined ASA children's health and dev...   \n",
       "25926  The following data sets for the period 1982-20...   \n",
       "44315  Survey of Earned DoctoratesSex; age; race-ethn...   \n",
       "13780  The TC record is taken from the International ...   \n",
       "...                                                  ...   \n",
       "2073   As in our prior work , we used tensor-based mo...   \n",
       "7798   The filling rate of TCs after making landfall ...   \n",
       "29013  This report documents the design, development,...   \n",
       "29355  [31] [32] [33] All C-11 Pittsburgh compound B ...   \n",
       "33185  Additional details may be found in the Early C...   \n",
       "\n",
       "                                                  labels  \\\n",
       "26309  Baltimore Longitudinal Study of Aging||Baltimo...   \n",
       "21490                 Early Childhood Longitudinal Study   \n",
       "25926      Optimum Interpolation Sea Surface Temperature   \n",
       "44315                        Survey of Earned Doctorates   \n",
       "13780                                            IBTrACS   \n",
       "...                                                  ...   \n",
       "2073                                                ADNI   \n",
       "7798                                             IBTrACS   \n",
       "29013                 Early Childhood Longitudinal Study   \n",
       "29355                                               ADNI   \n",
       "33185                 Early Childhood Longitudinal Study   \n",
       "\n",
       "                                        dedup_labels  \\\n",
       "26309   Baltimore Longitudinal Study of Aging (BLSA)   \n",
       "21490             Early Childhood Longitudinal Study   \n",
       "25926  Optimum Interpolation Sea Surface Temperature   \n",
       "44315                    Survey of Earned Doctorates   \n",
       "13780                                        IBTrACS   \n",
       "...                                              ...   \n",
       "2073                                            ADNI   \n",
       "7798                                         IBTrACS   \n",
       "29013             Early Childhood Longitudinal Study   \n",
       "29355                                           ADNI   \n",
       "33185             Early Childhood Longitudinal Study   \n",
       "\n",
       "                                               predicted  \\\n",
       "26309                                                      \n",
       "21490  (4ef2b977-2e2d-41f5-8ed6-3f44c691f620, S794046, )   \n",
       "25926  (4ef2b977-2e2d-41f5-8ed6-3f44c691f620, S794046, )   \n",
       "44315  (4ef2b977-2e2d-41f5-8ed6-3f44c691f620, S794046, )   \n",
       "13780  ibtracs|international best track archive for c...   \n",
       "...                                                  ...   \n",
       "2073                                                       \n",
       "7798                                                       \n",
       "29013  (4ef2b977-2e2d-41f5-8ed6-3f44c691f620, S794046, )   \n",
       "29355                                pittsburgh compound   \n",
       "33185  (4ef2b977-2e2d-41f5-8ed6-3f44c691f620, S794046, )   \n",
       "\n",
       "                                cleaned_dedup_labels  \\\n",
       "26309    baltimore longitudinal study of aging blsa    \n",
       "21490             early childhood longitudinal study   \n",
       "25926  optimum interpolation sea surface temperature   \n",
       "44315                    survey of earned doctorates   \n",
       "13780                                        ibtracs   \n",
       "...                                              ...   \n",
       "2073                                            adni   \n",
       "7798                                         ibtracs   \n",
       "29013             early childhood longitudinal study   \n",
       "29355                                           adni   \n",
       "33185             early childhood longitudinal study   \n",
       "\n",
       "                                                 pred_v2  \n",
       "26309                                                     \n",
       "21490                                                     \n",
       "25926                                                     \n",
       "44315                                                     \n",
       "13780  ibtracs|international best track archive for c...  \n",
       "...                                                  ...  \n",
       "2073                                                      \n",
       "7798                                                      \n",
       "29013                                                     \n",
       "29355                                pittsburgh compound  \n",
       "33185                                                     \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Model performance is evaluated by using a simulation study and two sets of data of Alzheimer's disease patients (one from the memory-clinic-based Amsterdam Dementia Cohort and one from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database).\""
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[combined['sid']=='S1119852'].sentence.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>sid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>dedup_labels</th>\n",
       "      <th>predicted</th>\n",
       "      <th>cleaned_dedup_labels</th>\n",
       "      <th>pred_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46399</th>\n",
       "      <td>f53dcc84-0b71-4efa-b434-625fd0596226</td>\n",
       "      <td>S6759109</td>\n",
       "      <td>The researchers noticed the genome sequence of...</td>\n",
       "      <td>genome sequence of SARS-CoV-2</td>\n",
       "      <td>genome sequence of SARS-CoV-2</td>\n",
       "      <td></td>\n",
       "      <td>genome sequence of sars cov 2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        fid       sid  \\\n",
       "46399  f53dcc84-0b71-4efa-b434-625fd0596226  S6759109   \n",
       "\n",
       "                                                sentence  \\\n",
       "46399  The researchers noticed the genome sequence of...   \n",
       "\n",
       "                              labels                   dedup_labels predicted  \\\n",
       "46399  genome sequence of SARS-CoV-2  genome sequence of SARS-CoV-2             \n",
       "\n",
       "                cleaned_dedup_labels pred_v2  \n",
       "46399  genome sequence of sars cov 2          "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = combined[combined['sid']=='S6759109']\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 1 sentences to process\n",
      "Relations O\n",
      "##hip O\n",
      "among O\n",
      "weights O\n",
      ", O\n",
      "universe O\n",
      "flags B-D\n",
      ", I-D\n",
      "populations I-D\n",
      ", I-D\n",
      "and I-D\n",
      "respond I-D\n",
      "##ents O\n",
      ": O\n",
      "2002 O\n",
      "– O\n",
      "06 O\n",
      "Weight O\n",
      "B O\n",
      "##Y O\n",
      "##ST O\n",
      "##U O\n",
      "##W O\n",
      "##T O\n",
      "B O\n",
      "##Y O\n",
      "##EX O\n",
      "##P O\n",
      "##W O\n",
      "##T O\n",
      "F1 O\n",
      "##P O\n",
      "##NL O\n",
      "##W O\n",
      "##T O\n",
      "Universe O\n",
      "flag O\n",
      "G O\n",
      "##10 O\n",
      "##CO O\n",
      "##H O\n",
      "##RT O\n",
      "G O\n",
      "##10 O\n",
      "##CO O\n",
      "##H O\n",
      "##RT O\n",
      "G O\n",
      "##10 O\n",
      "##CO O\n",
      "##H O\n",
      "##RT O\n",
      "Population O\n",
      "A O\n",
      "— O\n",
      "Spring O\n",
      "2002 O\n",
      "10th O\n",
      "- O\n",
      "grade O\n",
      "##r O\n",
      "A O\n",
      "— O\n",
      "Spring O\n",
      "2002 O\n",
      "10th O\n",
      "- O\n",
      "grade O\n",
      "##r O\n",
      "A O\n",
      "— O\n",
      "Spring O\n",
      "2002 O\n",
      "10th O\n",
      "- O\n",
      "grade O\n",
      "##r O\n",
      "Re O\n",
      "##sp O\n",
      "##ond O\n",
      "##ent O\n",
      "Full O\n",
      "##y O\n",
      "or O\n",
      "partially O\n",
      "completed O\n",
      "question O\n",
      "##naire O\n",
      "in O\n",
      "2002 O\n",
      "Full O\n",
      "##y O\n",
      "or O\n",
      "partially O\n",
      "completed O\n",
      "question O\n",
      "##naire O\n",
      "in O\n",
      "2002 O\n",
      "or O\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['flags populations and respond']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single = combined[combined['sid']=='S3351012']\n",
    "r = predict_df(single,debug=True)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>sid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>dedup_labels</th>\n",
       "      <th>predicted</th>\n",
       "      <th>cleaned_dedup_labels</th>\n",
       "      <th>pred_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dc107d04-1082-426a-b616-e755486c8627</td>\n",
       "      <td>S2682021</td>\n",
       "      <td>SeaWiFS ORM-derived g i ͑443͒ as a function of...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>430aa11c-0283-411b-8edc-08f5df3db258</td>\n",
       "      <td>S4365895</td>\n",
       "      <td>Foreign direct investment (FDI): Ownership or ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14848a9b-13a7-41c3-b49f-ba725695e497</td>\n",
       "      <td>S772899</td>\n",
       "      <td>As Sorokin (1959, p. 8) wrote, 2 At the presen...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c3de175-0bcf-4165-a5c3-c3ced789d2f6</td>\n",
       "      <td>S1088866</td>\n",
       "      <td>worth noting when using information from clini...</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>adni</td>\n",
       "      <td>adni</td>\n",
       "      <td>adni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da369ee6-2d60-402c-b3bf-05f44df77c78</td>\n",
       "      <td>S856664</td>\n",
       "      <td>The authors presented an electroencephalogram ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48307</th>\n",
       "      <td>7c3a786f-9fae-4b32-a036-603b96f98354</td>\n",
       "      <td>S1955800</td>\n",
       "      <td>The first mode (CEOF1) is the deep overturning...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48308</th>\n",
       "      <td>4e07d309-3f36-427c-95c5-89d3d88ad5e1</td>\n",
       "      <td>S1404663</td>\n",
       "      <td>The model is additive, which means in practice...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48309</th>\n",
       "      <td>a5e4464b-1ad9-4890-a411-8d84de0aadaa</td>\n",
       "      <td>S1088230</td>\n",
       "      <td>(2015) , who found that APOE was not significa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48310</th>\n",
       "      <td>a3698b97-2893-49a2-ade8-f53d1fef069b</td>\n",
       "      <td>S2002726</td>\n",
       "      <td>The disease diagnosis machine can therefore be...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48311</th>\n",
       "      <td>4ef2b977-2e2d-41f5-8ed6-3f44c691f620</td>\n",
       "      <td>S794046</td>\n",
       "      <td>Finally, ADNI aimed to create a data repositor...</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>adni</td>\n",
       "      <td>adni</td>\n",
       "      <td>adni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48312 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        fid       sid  \\\n",
       "0      dc107d04-1082-426a-b616-e755486c8627  S2682021   \n",
       "1      430aa11c-0283-411b-8edc-08f5df3db258  S4365895   \n",
       "2      14848a9b-13a7-41c3-b49f-ba725695e497   S772899   \n",
       "3      5c3de175-0bcf-4165-a5c3-c3ced789d2f6  S1088866   \n",
       "4      da369ee6-2d60-402c-b3bf-05f44df77c78   S856664   \n",
       "...                                     ...       ...   \n",
       "48307  7c3a786f-9fae-4b32-a036-603b96f98354  S1955800   \n",
       "48308  4e07d309-3f36-427c-95c5-89d3d88ad5e1  S1404663   \n",
       "48309  a5e4464b-1ad9-4890-a411-8d84de0aadaa  S1088230   \n",
       "48310  a3698b97-2893-49a2-ade8-f53d1fef069b  S2002726   \n",
       "48311  4ef2b977-2e2d-41f5-8ed6-3f44c691f620   S794046   \n",
       "\n",
       "                                                sentence labels dedup_labels  \\\n",
       "0      SeaWiFS ORM-derived g i ͑443͒ as a function of...                       \n",
       "1      Foreign direct investment (FDI): Ownership or ...                       \n",
       "2      As Sorokin (1959, p. 8) wrote, 2 At the presen...                       \n",
       "3      worth noting when using information from clini...   ADNI         ADNI   \n",
       "4      The authors presented an electroencephalogram ...                       \n",
       "...                                                  ...    ...          ...   \n",
       "48307  The first mode (CEOF1) is the deep overturning...                       \n",
       "48308  The model is additive, which means in practice...                       \n",
       "48309  (2015) , who found that APOE was not significa...                       \n",
       "48310  The disease diagnosis machine can therefore be...                       \n",
       "48311  Finally, ADNI aimed to create a data repositor...   ADNI         ADNI   \n",
       "\n",
       "      predicted cleaned_dedup_labels pred_v2  \n",
       "0                                             \n",
       "1                                             \n",
       "2                                             \n",
       "3          adni                 adni    adni  \n",
       "4                                             \n",
       "...         ...                  ...     ...  \n",
       "48307                                         \n",
       "48308                                         \n",
       "48309                                         \n",
       "48310                                         \n",
       "48311      adni                 adni    adni  \n",
       "\n",
       "[48312 rows x 8 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xji",
   "language": "python",
   "name": "xji"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
